{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5-6X-kiB_-z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "path = \"Dataset\"\n",
        "labelFile = 'labels.csv'\n",
        "batch_size_val=32\n",
        "epochs_val=10\n",
        "imageDimesions = (32,32,3)\n",
        "testRatio = 0.2\n",
        "validationRatio = 0.2\n",
        "\n",
        "count = 0\n",
        "images = []\n",
        "classNo = []\n",
        "myList = os.listdir(path)\n",
        "print(\"Total Classes Detected:\",len(myList))\n",
        "noOfClasses=len(myList)\n",
        "print(\"Importing Classes.....\")\n",
        "for x in range (0,len(myList)):\n",
        "    myPicList = os.listdir(path+\"/\"+str(count))\n",
        "    for y in myPicList:\n",
        "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
        "        images.append(curImg)\n",
        "        classNo.append(count)\n",
        "    print(count, end =\" \")\n",
        "    count +=1\n",
        "print(\" \")\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n",
        "\n",
        "\n",
        "print(\"Data Shapes\")\n",
        "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\n",
        "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\n",
        "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\n",
        "\n",
        "\n",
        "data=pd.read_csv(labelFile)\n",
        "print(\"data shape \",data.shape,type(data))\n",
        "\n",
        "num_of_samples = []\n",
        "cols = 5\n",
        "num_classes = noOfClasses\n",
        "\n",
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "def equalize(img):\n",
        "    img =cv2.equalizeHist(img)\n",
        "    return img\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "\n",
        "X_train=np.array(list(map(preprocessing,X_train)))\n",
        "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
        "X_test=np.array(list(map(preprocessing,X_test)))\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "\n",
        "\n",
        "dataGen= ImageDataGenerator(width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            zoom_range=0.2,\n",
        "                            shear_range=0.1,\n",
        "                            rotation_range=10)\n",
        "dataGen.fit(X_train)\n",
        "batches= dataGen.flow(X_train,y_train,batch_size=20)\n",
        "X_batch,y_batch = next(batches)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train,noOfClasses)\n",
        "y_validation = to_categorical(y_validation,noOfClasses)\n",
        "y_test = to_categorical(y_test,noOfClasses)\n",
        "\n",
        "\n",
        "def myModel():\n",
        "    model= Sequential()\n",
        "    model.add((Conv2D(60,(5,5),input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
        "    model.add((Conv2D(60, (5,5), activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add((Conv2D(30, (3,3),activation='relu')))\n",
        "    model.add((Conv2D(30, (3,3), activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(noOfClasses,activation='softmax'))\n",
        "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = myModel()\n",
        "print(model.summary())\n",
        "history=model.fit_generator(dataGen.flow(X_train,y_train,batch_size=batch_size_val),steps_per_epoch=len(X_train)//32,epochs=epochs_val,validation_data=(X_validation,y_validation),shuffle=1)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Acurracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "score =model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test Score:',score[0])\n",
        "print('Test Accuracy:',score[1])\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "output:\n",
        "Total Classes Detected: 43\n",
        "Importing Classes.....\n",
        "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n",
        "Data Shapes\n",
        "Shapes\n",
        "Train(22271, 32, 32, 3) (22271,)\n",
        "Validation(5568, 32, 32, 3) (5568,)\n",
        "Test(6960, 32, 32, 3) (6960,)\n",
        "data shape  (43, 2) <class 'pandas.core.frame.DataFrame'>\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 28, 28, 60)        1560\n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 24, 24, 60)        90060\n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 12, 12, 60)        0\n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 10, 10, 30)        16230\n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 8, 8, 30)          8130\n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 30)          0\n",
        "_________________________________________________________________\n",
        "dropout (Dropout)            (None, 4, 4, 30)          0\n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 480)               0\n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 500)               240500\n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 500)               0\n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 43)                21543\n",
        "=================================================================\n",
        "Total params: 0\n",
        "Trainable params: 0\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n",
        "WARNING:tensorflow:From <ipython-input-1-370825436516>:118: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
        "Instructions for updating:\n",
        "Please use Model.fit, which supports generators.\n",
        "Epoch 1/10\n",
        "695/695 [==============================] - 141s 202ms/step - loss: 2.5258 - accuracy: 0.2969 - val_loss: 0.9100 - val_accuracy: 0.7204\n",
        "Epoch 2/10\n",
        "695/695 [==============================] - 114s 164ms/step - loss: 1.2834 - accuracy: 0.6061 - val_loss: 0.3512 - val_accuracy: 0.9023\n",
        "Epoch 3/10\n",
        "695/695 [==============================] - 111s 159ms/step - loss: 0.8758 - accuracy: 0.7286 - val_loss: 0.2079 - val_accuracy: 0.9407\n",
        "Epoch 4/10\n",
        "695/695 [==============================] - 109s 157ms/step - loss: 0.6474 - accuracy: 0.8003 - val_loss: 0.1500 - val_accuracy: 0.9562\n",
        "Epoch 5/10\n",
        "695/695 [==============================] - 104s 149ms/step - loss: 0.5545 - accuracy: 0.8255 - val_loss: 0.1222 - val_accuracy: 0.9644\n",
        "Epoch 6/10\n",
        "695/695 [==============================] - 105s 151ms/step - loss: 0.4677 - accuracy: 0.8526 - val_loss: 0.0913 - val_accuracy: 0.9707\n",
        "Epoch 7/10\n",
        "695/695 [==============================] - 104s 150ms/step - loss: 0.4187 - accuracy: 0.8696 - val_loss: 0.0830 - val_accuracy: 0.9731\n",
        "Epoch 8/10\n",
        "695/695 [==============================] - 103s 149ms/step - loss: 0.3727 - accuracy: 0.8834 - val_loss: 0.0623 - val_accuracy: 0.9815\n",
        "Epoch 9/10\n",
        "695/695 [==============================] - 106s 152ms/step - loss: 0.3454 - accuracy: 0.8922 - val_loss: 0.0970 - val_accuracy: 0.9718\n",
        "Epoch 10/10\n",
        "695/695 [==============================] - 109s 157ms/step - loss: 0.3262 - accuracy: 0.8992 - val_loss: 0.0583 - val_accuracy: 0.9817\n",
        "\n",
        "\n",
        "Test Score: 0.04966879263520241\n",
        "Test Accuracy: 0.9850574731826782"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTzC5yxwOmiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3QcmeBkNNm_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}